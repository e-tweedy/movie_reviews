{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115feb9d",
   "metadata": {},
   "source": [
    "# Training a RNN to recognize movie review sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ff0644",
   "metadata": {},
   "source": [
    "This was built following a tutorial in the wonderful book Machine Learning with PyTorch and Scikit-Learn by Raschka, Liu and Mirjalili (2022, Packt Publishing). In this notebook, we do the following:\n",
    "\n",
    "1. Use the PyTorch library (https://pytorch.org/) to construct and train a recurrent neural network (RNN) on the IMDB dataset build in to torchtext.datasets : https://pytorch.org/text/stable/datasets.html#imdb\n",
    "2. Deploy the trained model as an interactive web app using the Gradio library (https://gradio.app/).\n",
    "\n",
    "Note that the Gradio app can be found by visiting my huggingface page: https://huggingface.co/spaces/etweedy/movie_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272eb712",
   "metadata": {},
   "source": [
    "First we import out libraries and set the gpu device if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0e04187-891e-4dc4-8fb4-b8dfec42d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install torchtext==0.13.0\n",
    "! pip install torchdata==0.4.0\n",
    "\n",
    "import torch\n",
    "import torchdata\n",
    "from torchtext.datasets import IMDB\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed596fb2",
   "metadata": {},
   "source": [
    "Import the data into training and validation Dataset items.  Each of these is a list of tuples of the form (sentiment,review), where the sentiment is either 'pos' or 'neg' and review is a string containing a review for a movie.  The review strings can contain HTML tags, as demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49cda264-b7e8-4b82-9f73-ce58e85b47bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = list(IMDB(split='train'))\n",
    "ds_val = list(IMDB(split='test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aa63f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neg',\n",
       " 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6c5c237-c5f9-4030-959e-1153e71ef624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735e4e51",
   "metadata": {},
   "source": [
    "This tokenizer function does a few things:\n",
    "1. Removes HTML tags, which are common in this dataset.\n",
    "2. Finds any emoticons with eyes like : or ; or = , with or without a nose like -, and with mouth like ) or ( or P or D.\n",
    "3. Removes any non-character symbols and joins on the standardized emoticons.\n",
    "4. Splits into a list of token strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fefea606-5a13-42ce-92c2-3c8c05544a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>','',text)\n",
    "    emoticons = re.findall(\n",
    "        '(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',text.lower()\n",
    "    )\n",
    "    text = (re.sub('[\\W]+',' ',text.lower())+' '.join(emoticons).replace('-',''))\n",
    "    tokenized = text.split()\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db85c7ba",
   "metadata": {},
   "source": [
    "We build a collections.Counter() container which keeps track of the unique words coming from the tokenized reviews in the training set, and the number of times each word appears among all reviews in the training set.  We see the size of the vocabulary is 75977 words.  We take a look at the token list for the final review from ds_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9228221c-1218-4de9-9b56-37973984a187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab-size: 75977\n"
     ]
    }
   ],
   "source": [
    "token_counts = Counter()\n",
    "for label, line in ds_train:\n",
    "    tokens = tokenizer(line)\n",
    "    token_counts.update(tokens)\n",
    "\n",
    "print('Vocab-size:',len(token_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65a06633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pos',\n",
       " 'The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3fd7c77-f7b0-4c22-92a4-eae5224f9980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'story', 'centers', 'around', 'barry', 'mckenzie', 'who', 'must', 'go', 'to', 'england', 'if', 'he', 'wishes', 'to', 'claim', 'his', 'inheritance', 'being', 'about', 'the', 'grossest', 'aussie', 'shearer', 'ever', 'to', 'set', 'foot', 'outside', 'this', 'great', 'nation', 'of', 'ours', 'there', 'is', 'something', 'of', 'a', 'culture', 'clash', 'and', 'much', 'fun', 'and', 'games', 'ensue', 'the', 'songs', 'of', 'barry', 'mckenzie', 'barry', 'crocker', 'are', 'highlights']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b57b91",
   "metadata": {},
   "source": [
    "We then sort the list of items in token_counts in descending order of incidence and convert it into a torchtext.vocab object.  Finally, we insert the padding token as well as the placeholder token for unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36d6811b-ff99-4858-8635-060bc0c8c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "213d5f44-186a-43e3-94e7-20a44b411fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_freq_tuples = sorted(token_counts.items(),key=lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbb3a1c3-0143-4d53-80d9-24f30e984735",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaa6b315-e915-4d6f-95ef-ba1056509a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vocab(ordered_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4237633b-6250-4f06-a2af-352c03eb0e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.insert_token('<pad>',0)\n",
    "vocab.insert_token('<unk>',1)\n",
    "vocab.set_default_index(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47a90eb",
   "metadata": {},
   "source": [
    "The pipeline for labels converts 'pos' to 1 and 'neg' to 0.\n",
    "The pipeline converts a string to the list of vocab codes for tokens in tokenizer(string).\n",
    "\n",
    "The collate_batch function will serve as our collate_fn for the DataLoader we'll define.  Given a batch of samples, collate_batch does a few things:\n",
    "1. Creates label_list, a list of target labels 1 or 0 for the batch samples.\n",
    "2. Creates lengths, a list of word counts of each sample in the batch.\n",
    "3. Creates text_list, a list of lists of vocab codes of tokens in tokenized samples from the batch.\n",
    "4. Uses pad_sequence() to pad all lists in text_list with 0 (the pad token code) so that all sequences in the batch are the same length, namely max(lengths)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c03696e4-ff82-4b38-930f-189cdbb5886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline=lambda x: [vocab[token] for token in tokenizer(x)]\n",
    "label_pipeline=lambda x: 1. if x=='pos' else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d55da22b-bc59-49d8-bb0c-dbbeda8c2f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list,text_list,lengths=[],[],[]\n",
    "    for _label,_text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text=torch.tensor(text_pipeline(_text),dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    padded_text_list=nn.utils.rnn.pad_sequence(text_list,batch_first=True)\n",
    "    return padded_text_list , label_list, lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943d0353",
   "metadata": {},
   "source": [
    "Finally we create training and validation DataLoaders with batch size of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd97600d-9be6-40c1-aed4-45a469a77de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96919715-8be0-4309-95f3-d696d1a1f669",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "dl_train = DataLoader(ds_train,batch_size=batch_size,shuffle=True,collate_fn=collate_batch)\n",
    "dl_val = DataLoader(ds_val,batch_size=batch_size,shuffle=True,collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2bda4b",
   "metadata": {},
   "source": [
    "Training and evaluation functions (for a single epoch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25963fe2-8f48-4b67-b004-67dc1a815ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc,total_loss=0,0\n",
    "    for text_batch, label_batch, lengths in dataloader:\n",
    "        text_batch = text_batch.to(device)\n",
    "        label_batch = label_batch.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        opt.zero_grad()\n",
    "        pred=model(text_batch,lengths)[:,0]\n",
    "        loss = loss_fn(pred,label_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_acc += ((pred>0.5).float() == label_batch).float().sum().item()\n",
    "        total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset),total_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d8ee122-4cb5-42dc-9214-dc3920131c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc,total_loss=0,0\n",
    "    count=1\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "#            print(f'Batch {count}')\n",
    "            count+=1\n",
    "            text_batch = text_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            pred=model(text_batch,lengths)[:,0]\n",
    "            loss = loss_fn(pred,label_batch)\n",
    "            total_acc += ((pred>0.5).float() == label_batch).float().sum().item()\n",
    "            total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset),total_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3f4cae",
   "metadata": {},
   "source": [
    "The RNN class that we'll use.  Note that there are:\n",
    "1. An input embedding layer\n",
    "2. A Long Short-Term Memory (LSTM) layer, which is a drop-in replacement for the ordinary RNN layer that helps to mitigate the vanishing/exploding gradient issues that can plague ordinary RNN's while still allowing the network to capture some long-term dependencies.\n",
    "3. Several FC layers with Dropout layers in-between to reduce potential of overfitting.\n",
    "4. Sigmoid output activation - we'll classify the output as 0 or 1 based on a threshold of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf9feb1e-d5a0-4303-807b-92e941453096",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_dim,rnn_hidden_size,dc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,embed_dim,padding_idx=0)\n",
    "        self.rnn = nn.LSTM(embed_dim,rnn_hidden_size,batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size,fc_hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(rnn_hidden_size,fc_hidden_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Linear(fc_hidden_size,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,text,lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out,lengths.cpu().numpy(),enforce_sorted=False,batch_first=True)\n",
    "        out,(hidden,cell) = self.rnn(out)\n",
    "        out = hidden[-1,:,:]\n",
    "        out=self.fc1(out)\n",
    "        out=self.relu1(out)\n",
    "        out=self.dropout1(out)\n",
    "        out=self.fc2(out)\n",
    "        out=self.relu2(out)\n",
    "        out=self.dropout2(out)\n",
    "        out=self.fc3(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e745a1c",
   "metadata": {},
   "source": [
    "We initialize our RNN instance with embedding dimension 20 and all hidden layers of size 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64cb9049-39f8-4531-86d3-0947c895f811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(75979, 20, padding_idx=0)\n",
       "  (rnn): LSTM(20, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size=len(vocab)\n",
    "embed_dim=20\n",
    "rnn_hidden_size=64\n",
    "fc_hidden_size=64\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size,embed_dim,rnn_hidden_size,fc_hidden_size)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b736a8b5",
   "metadata": {},
   "source": [
    "We use Binary Cross Entropy loss (ordinary BCELoss, since we included the output sigmoid).  We optimize with Adam; note that 0.001 is a typical baseline learning rate for Adam, but we scale up to 0.1 because we included dropout layers in our RNN - they typically allow for a faster learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "baeb334e-5a26-4173-8149-4030a57a7532",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "opt = torch.optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da2dc80-b848-44d1-a380-4829a00e86ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 --- training accuracy: 0.6946 --- validation accuracy: 0.8254\n",
      "Epoch 1 --- training accuracy: 0.8875 --- validation accuracy: 0.8689\n",
      "Epoch 2 --- training accuracy: 0.9345 --- validation accuracy: 0.8683\n",
      "Epoch 3 --- training accuracy: 0.9570 --- validation accuracy: 0.8531\n",
      "Epoch 4 --- training accuracy: 0.9716 --- validation accuracy: 0.8580\n",
      "Epoch 5 --- training accuracy: 0.9806 --- validation accuracy: 0.8526\n",
      "Epoch 6 --- training accuracy: 0.9842 --- validation accuracy: 0.8541\n",
      "Epoch 7 --- training accuracy: 0.9862 --- validation accuracy: 0.8530\n",
      "Epoch 8 --- training accuracy: 0.9864 --- validation accuracy: 0.8545\n"
     ]
    }
   ],
   "source": [
    "num_epochs=10\n",
    "torch.manual_seed(1)\n",
    "for epoch in range(num_epochs):\n",
    "    acc_train,loss_train = train(dl_train)\n",
    "    acc_val,loss_val = evaluate(dl_val)\n",
    "    print(f'Epoch {epoch} --- training accuracy: {acc_train:.4f} --- validation accuracy: {acc_val:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412792eb",
   "metadata": {},
   "source": [
    "Save our model weights and vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cbf7e1-97ae-4056-a51f-4a5b9f4eb05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'imdb_rnn_drop_model_lr_1e-2_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5435de-d801-4cbc-bae3-85a406757e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vocab,'imdb_rnn_drop_model_lr_1e-2_vocab.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81abcb0d-a726-4d5e-b812-8eb08e38c1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    text_list, lengths = [],[]\n",
    "    processed_text=torch.tensor(text_pipeline(text),dtype=torch.int64)\n",
    "    text_list.append(processed_text)\n",
    "    lengths.append(processed_text.size(0))\n",
    "    lengths=torch.tensor(lengths)\n",
    "    padded_text_list=nn.utils.rnn.pad_sequence(text_list,batch_first=True)\n",
    "    padded_text_list = padded_text_list.to(device)\n",
    "    length = lengths.to(device)\n",
    "    pred = model(padded_text_list,lengths)\n",
    "    \n",
    "    return 'Positive' if pred > 0.5 else 'Negative'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fceb593",
   "metadata": {},
   "source": [
    "Finally, we implement a little Gradio web app that we can use to interact with our model.  The app will ask the user to input a movie review into a text entry box, and will return a prediction of 'Positive' or 'Negative' sentiment.  The below code will generate a locally hosted app, but see the following blog post for a nice tutorial on deploying your web app on Hugging Face:\n",
    "https://huggingface.co/blog/gradio-spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cbf2c0a4-b8c0-438a-99ac-716d64210131",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install gradio\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1f2bb2e6-a14d-47ca-9c55-50b419285512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = \"Write a movie review\"\n",
    "description = \"Enter a review for a movie you've seen.  This tool will try to guess whether your review is positive or negative.\"\n",
    "gr.Interface(fn=predict, \n",
    "             inputs=\"text\",\n",
    "             outputs=\"label\",\n",
    "             title = title,\n",
    "             description = description,\n",
    "              ).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9df187-afcd-4f46-add3-fdeb77648e92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
